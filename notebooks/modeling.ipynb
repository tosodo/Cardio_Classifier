{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jx-6riWsewmg"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06ykjuY2ewmh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kn489jNKewmk"
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xdx_usdJewml"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/cardio.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EVCupeTtewnS"
   },
   "source": [
    "# Split the Data into feature data and target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rg1zurVLewnT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = df['cardio']\n",
    "x=df.drop(columns='cardio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Splitting data into 75% training data and 25% test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wA5A6wfdk4RU"
   },
   "outputs": [],
   "source": [
    "#Split data in 75% training data and 25% test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.25, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Standization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "LcIdHULAhffl",
    "outputId": "be8111fc-d2d2-4227-f9d4-9e54c7d35225"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.40622524, -1.3630344 , -0.73462899, ..., -0.31243322,\n",
       "        -0.23931996,  0.49648558],\n",
       "       [ 0.71822501, -2.03605939, -0.73462899, ..., -0.31243322,\n",
       "        -0.23931996,  0.49648558],\n",
       "       [ 0.77762764,  0.15147431, -0.73462899, ..., -0.31243322,\n",
       "        -0.23931996,  0.49648558],\n",
       "       ...,\n",
       "       [ 1.4595615 ,  0.45275626,  1.36123134, ..., -0.31243322,\n",
       "        -0.23931996,  0.49648558],\n",
       "       [-0.06077129,  1.09905463,  1.36123134, ...,  3.20068396,\n",
       "         4.17850639,  0.49648558],\n",
       "       [-0.2367945 , -1.63961446, -0.73462899, ..., -0.31243322,\n",
       "        -0.23931996,  0.49648558]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To standardize the features...\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std=StandardScaler()\n",
    "std.fit(x_train)\n",
    "std.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nj_0JJcgycYT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Libraries used \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report , accuracy_score , roc_auc_score\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Fitting the Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UkIsxxhlyPjl"
   },
   "outputs": [],
   "source": [
    "def base_func(element):\n",
    "    #train and fit the model\n",
    "    model = element()\n",
    "    model.fit(x_train , y_train)\n",
    "    \n",
    "    #predict\n",
    "    train_preds = model.predict(x_train)\n",
    "    test_preds = model.predict(x_test)\n",
    "    \n",
    "    #evaluation\n",
    "    train_accuracy = roc_auc_score(y_train , train_preds)\n",
    "    test_accuracy = roc_auc_score(y_test , test_preds)\n",
    "    \n",
    "    print(str(element))\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(f\"Training Accuracy: {(train_accuracy * 100) :.4}%\")\n",
    "    print(f\"Test Accuracy : {(test_accuracy * 100) :.4}%\")\n",
    "    \n",
    "    #Store accuracy in a new DataFrame\n",
    "    score_logreg = [element , train_accuracy , test_accuracy]\n",
    "    models = pd.DataFrame([score_logreg])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used 5 models to find the best model accuracy for better prediction and comparison .\n",
    "Categorical classifier prediction is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "m4IRMzvcewnW",
    "outputId": "324c3320-1dfb-433a-b26c-c63300ff7102"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tosodo/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "--------------------------------------------\n",
      "Training Accuracy: 71.19%\n",
      "Test Accuracy : 71.4%\n",
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "--------------------------------------------\n",
      "Training Accuracy: 71.3%\n",
      "Test Accuracy : 55.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tosodo/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "--------------------------------------------\n",
      "Training Accuracy: 98.14%\n",
      "Test Accuracy : 70.59%\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "--------------------------------------------\n",
      "Training Accuracy: 73.9%\n",
      "Test Accuracy : 73.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tosodo/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.svm.classes.SVC'>\n",
      "--------------------------------------------\n",
      "Training Accuracy: 100.0%\n",
      "Test Accuracy : 49.99%\n"
     ]
    }
   ],
   "source": [
    "##Five algorithms used\n",
    "algorithms = [LogisticRegression , KNeighborsClassifier , RandomForestClassifier , XGBClassifier ,svm.SVC]\n",
    "\n",
    "#running each model and print accuracy scores\n",
    "for element in algorithms:\n",
    "    base_func(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_P9hwZbuVLa"
   },
   "outputs": [],
   "source": [
    "def grd_src(classifier , param_grid):\n",
    "    param_grid = param_grid\n",
    "  \n",
    "  #Instantiate the tuned random forest model\n",
    "    grid_search = GridSearchCV(classifier, param_grid, cv=3, n_jobs=-1)\n",
    "  \n",
    "  #train the tuned random forest model\n",
    "    grid_search.fit(x_train , y_train)\n",
    "\n",
    "  #print best paramets during the grid search\n",
    "    print((str(classifier) + \"Best Parameters\"))\n",
    "    print(\"-----------------------------------\")\n",
    "    print(grid_search.best_params_)\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " splitting data in decision tree can use Gini Index or Entropy .\n",
    " Hyperparameter modeling to improve the fit ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "39gpc91twAjk",
    "outputId": "e5d07238-004c-4f58-a9cf-6e936d05ab04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)Best Parameters\n",
      "-----------------------------------\n",
      "{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 21}\n"
     ]
    }
   ],
   "source": [
    "##Grid Search for best parameters of RandomForestClassifier\n",
    "param_grid_rf = {\"n_estimators\" : [10,15,20,21,22],\n",
    "                 \"criterion\" : [\"gini\" , \"entropy\"],\n",
    "                 \"max_depth\" : [8,9,10,11],\n",
    "                 \"min_samples_split\" : [2,3,4,5,6,7]}\n",
    "\n",
    "rf_params = grd_src(RandomForestClassifier() , param_grid_rf)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "_Z5ElirnwZ_i",
    "outputId": "32c6f222-81fd-46d6-ad20-9e92766fab7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)Best Parameters\n",
      "-----------------------------------\n",
      "{'colsample_by_tree': 0, 'gamma': 0.2, 'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "#GridSearch for best parameters of XGBClassifier\n",
    "param_grid_xgb = {\"n_estimators\" : [120,100,90,80,60,],\n",
    "                  \"learning_rate\" : [0.01,0.1,0.2] , \n",
    "                  \"max_depth\" : [2,3,4,5],\n",
    "                  \"colsample_by_tree\" : [0,0.02],\n",
    "                  \"gamma\":[0,0.01,0.1,0.2]}\n",
    "\n",
    "xg_param = grd_src(XGBClassifier() , param_grid_xgb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xgboost_model.pkl', 'wb') as pickle_file:\n",
    "    pkl.dump(xg_param, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rf_model.pkl', 'wb') as pickle_file:\n",
    "    pkl.dump(rf_params, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/pickled_diamonds.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9992c7149745>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/pickled_diamonds.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpickle_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_diamonds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/pickled_diamonds.pkl'"
     ]
    }
   ],
   "source": [
    "with open('data/pickled_diamonds.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(my_diamonds, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rf_model.pkl','rb') as pickle_file:\n",
    "    rf_params = pkl.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xgboost_model.pkl','rb') as pickle_file:\n",
    "    xg_param = pkl.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0Q2M7zKwmzF"
   },
   "outputs": [],
   "source": [
    "#Run models with their best parameters and also print accuracy scores\n",
    "from sklearn import metrics\n",
    "def  run_model(model, x_train, y_train,x_test, y_test ):\n",
    "     model.fit(x_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    train_preds = model.predict_proba(x_train).argmax(1)\n",
    "    test_preds = model.predict_proba(x_test).argmax(1)\n",
    "\n",
    "    \n",
    "\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, test_preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.gcf().savefig('roc.png')\n",
    "\n",
    "    # evaluate\n",
    "    train_auc = roc_auc_score(y_train, train_preds)\n",
    "    test_auc = roc_auc_score(y_test, test_preds)\n",
    "    report = classification_report(y_test, test_preds)\n",
    "\n",
    "    print(metrics.confusion_matrix(y_test, test_preds))\n",
    "\n",
    "    test_preds[test_preds>roc_auc]= 1\n",
    "    test_preds[test_preds<=roc_auc]= 0\n",
    "\n",
    "    #print reports of the model accuracy\n",
    "       print('Model Scores')\n",
    "    print(\"------------------------\")\n",
    "    print(f\"Training AUC: {(train_auc * 100):.4}%\")\n",
    "    print(f\"Test AUC:     {(test_auc * 100):.4}%\")\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print('Classification Report : \\n', report)\n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "colab_type": "code",
    "id": "rzov1CP6wn2W",
    "outputId": "d50b694a-6da7-45ab-e12a-457e29d98e96"
   },
   "outputs": [],
   "source": [
    "#Random forest with best parameters\n",
    "#{'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 5, 'n_estimators': 20}\n",
    "rf_model=RandomForestClassifier(n_estimators=20, \n",
    "                                  criterion= 'gini', \n",
    "                                  max_depth= 9, \n",
    "                                  min_samples_split= 5)\n",
    "rfc_cv_score = cross_val_score(rf_model, x, y, cv=3, scoring='roc_auc')\n",
    "\n",
    "                               \n",
    "                               \n",
    "run_model(rf_model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "colab_type": "code",
    "id": "h3CspTnNMFrd",
    "outputId": "b6c24869-b34f-42e3-f930-8ef8422d7762"
   },
   "outputs": [],
   "source": [
    "##Xg boost with the best parameters\n",
    "#{'colsample_by_tree': 0, 'gamma': 0.2, 'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 80}\n",
    "\n",
    "\n",
    "xgb_model = XGBClassifier(colsample_by_tree = 0 , n_estimators = 80\n",
    "                          , gamma = 0.2 , learning_rate = 0.2 , \n",
    "                          max_depth = 4)\n",
    "\n",
    "\n",
    "run_model(xgb_model , x_train , y_train , x_test , y_test)\n",
    "xgb_cv_score = cross_val_score(xgb_model, x, y, cv=3, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Classifier_Cardiovascular_new.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
